{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encoder_test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGwVArYbDviP"
      },
      "source": [
        "# Encoder test\n",
        "Testing encoder with data from the data_processing module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R40pRaXRrIUH"
      },
      "source": [
        "Instructions:\n",
        " - Upload DataProcessing.py, config.yml, process.py, utils.py and encoder.py\n",
        " - In DataProcessing.py, change *from data_processing.utils import ** to *from utils import **."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNh6TDs0DviW"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PBWyneDDviX",
        "scrolled": true
      },
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install tensorflow\n",
        "!{sys.executable} -m pip install tensorflow-addons\n",
        "!{sys.executable} -m pip install -q tensorflow-io\n",
        "!{sys.executable} -m pip install pyyaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8iA4AEDDviZ"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow as tf\n",
        "import importlib\n",
        "import yaml\n",
        "\n",
        "from google.colab import auth\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm \n",
        "from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFPD70WjTqFs"
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9a7c9_zTWS5",
        "outputId": "d9f12198-8e26-434d-ea7c-b3f1bfad790f"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  90607      0 --:--:-- --:--:-- --:--:-- 90607\n",
            "OK\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 10.8 MB of archives.\n",
            "After this operation, 23.1 MB of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.35.0_amd64.deb ...\n",
            "Unpacking gcsfuse (0.35.0) ...\n",
            "Setting up gcsfuse (0.35.0) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8AduZ0zTdP9",
        "outputId": "820602b2-8399-4624-d770-5521a14c14f6"
      },
      "source": [
        "!mkdir DataSet\n",
        "!gcsfuse --implicit-dirs spade_dataset DataSet"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/04/30 07:12:02.449791 Using mount point: /content/DataSet\n",
            "2021/04/30 07:12:02.458278 Opening GCS connection...\n",
            "2021/04/30 07:12:02.686089 Mounting file system \"spade_dataset\"...\n",
            "2021/04/30 07:12:02.703014 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCdg4_dDvia"
      },
      "source": [
        "### Process data and load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkd_EsSfDviZ"
      },
      "source": [
        "import DataProcessing as dp \n",
        "from encoder import Encoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhrv2Y6kDvia"
      },
      "source": [
        "config = yaml.load(Path(\"config.yml\").read_text(), Loader=yaml.SafeLoader)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLAUEn-_Dvib"
      },
      "source": [
        "set_type = \"val\"\n",
        "base_path = \"DataSet/cityscape/processed_data\"\n",
        "reader = dp.DataReader(base_path, set_type)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soc_YOt7Dvib",
        "outputId": "159bd56e-34ae-4c26-8901-a2234f01398f"
      },
      "source": [
        "reader.read_data_set()\n",
        "data_set = reader.get_dataset()\n",
        "type(data_set)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.MapDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl9nDsjor5M_",
        "outputId": "bb66cf2a-ee27-4745-aaa6-6ed7bba641df"
      },
      "source": [
        "for example in data_set.take(1):\n",
        "  print(example.keys())\n",
        "  print(example[\"label\"])\n",
        "  print(example[\"subset\"])\n",
        "\n",
        "  img_masked = example[\"img_masked\"]\n",
        "  img_original = example[\"img_original\"]\n",
        "\n",
        "  \n",
        "  # Check images.\n",
        "  img_masked = Image.fromarray(img_masked.numpy(), 'RGB')\n",
        "  img_masked.save(\"img_masked.jpg\")\n",
        "\n",
        "  img_original = Image.fromarray(img_original.numpy(), 'RGB')\n",
        "  img_original.save(\"img_original.jpg\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['label', 'subset', 'img_masked', 'img_original'])\n",
            "tf.Tensor(b'frankfurt_000000_000294', shape=(), dtype=string)\n",
            "tf.Tensor(b'val', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h61n8BvDvic"
      },
      "source": [
        "### Encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l51DVl6HDvic"
      },
      "source": [
        "encoder = Encoder()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyppBw0HDvic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bccc73-4975-43e4-b69c-24d60d0657ae"
      },
      "source": [
        "encoder(tf.reshape(img_original, (-1, *img_original.shape)))[0].shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRAgn8adtU8_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}